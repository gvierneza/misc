{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvierneza/misc/blob/master/VerUno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIrFe2YCWsKj",
        "colab_type": "text"
      },
      "source": [
        "# Simple Page Scraper for *Veritas Uno Challenge 2019*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1k6k6oNAVqI",
        "colab_type": "text"
      },
      "source": [
        "(hit ctrl-F9 while connected to the Interwebs to run all of this...it should all run as long as you can get to the url held in score_page)<br />  This application scrapes the current Veritas Uno Challenge results from the free service that we have used to host the leaderboard and reformats and calculates the percentage of wins for each player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqorXqCTXspR",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_KzhFc8CEiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib2 #library for reading from the Interwebs.\n",
        "from bs4 import BeautifulSoup #hugely popular Python parsing library, in our case for HTML\n",
        "import re #regular expressions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhLoDp8lXw0b",
        "colab_type": "text"
      },
      "source": [
        "Setup the specific source page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml0WarM4CK-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_page = 'https://keepthescore.co/game/trdfqrmttse/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzIVzZWmYEe9",
        "colab_type": "text"
      },
      "source": [
        "Get the source _N.B., This user agent (or at least some user agent) is required_ for the keepthsecore site or it returns 403s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siDDmyHLCW8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  request=urllib2.Request(score_page,None,headers={'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7',}\n",
        "  )\n",
        "  page = urllib2.urlopen(request)\n",
        "  soup = BeautifulSoup(page,'html.parser') #docs at https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "except:\n",
        "  print('Something evil this way has already come.  You are probably not connected to the Interwebs.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGogELQNYhTn",
        "colab_type": "text"
      },
      "source": [
        "Parse the source...there are no really good markers to use, I just pulled these out because they seemed as logical as any.<br />\n",
        "The first find_all grabs the players from their row\n",
        "and the second grabs them from the top scoring row.  Note that the player row has a blank td in it but it doesn't matter as it also doesn't have a title attribute so it isn't found.  The scores row DOES have a value for the first item but it isn't a real score. So, we have to start grabbing the scores from the [1] item in the scores array.  The iter_counter keeps track of that for us.  <br />The named capture group in the regex grabs the score which is converted to an int so that it can be logically added to the total number of games.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXqpOpEHIK6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "player_box = soup.find_all('a',attrs={'title': 'Edit or delete player'})\n",
        "scores = soup.find('tr', attrs={'class': 'info'}).find_all('th')\n",
        "players = {}\n",
        "iter_counter = game_total = 0\n",
        "for player in player_box:\n",
        "  iter_counter+=1\n",
        "  m = re.match(r\"^(?P<score>\\d+).*$\",scores[iter_counter].text.strip())\n",
        "  players[player.text.strip()] = int_score = int(m.group('score'))\n",
        "  game_total+=int_score\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILy5yHnmaq8b",
        "colab_type": "text"
      },
      "source": [
        "Sort the items in the dictionary by the values and print them out, calculating the percentage as it flows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmH1fNoa0T08",
        "colab_type": "code",
        "outputId": "0b99d5f2-f062-44c1-952d-942a1866b921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "s_dict = sorted(players.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"{} games played\".format(game_total))\n",
        "print \"{:<15} {:<5} % of total\".format('Name', 'wins')\n",
        "for k, v in s_dict:\n",
        "  percentage_of_total = float(v)/float(game_total) * 100\n",
        "  print \"{:<15} {:<5}  {:.2f}%\".format(k, v, percentage_of_total)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "481 games played\n",
            "Name            wins  % of total\n",
            "Matthew         135    28.07%\n",
            "Eric whatever   106    22.04%\n",
            "Chad            97     20.17%\n",
            "Pawel           84     17.46%\n",
            "Anjula          35     7.28%\n",
            "Wild Bill       5      1.04%\n",
            "Abby            5      1.04%\n",
            "Talia           4      0.83%\n",
            "John            4      0.83%\n",
            "Tim             3      0.62%\n",
            "Bill 2.X        2      0.42%\n",
            "Josh k          1      0.21%\n",
            "Scott           0      0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5y_3kfa6RAb",
        "colab_type": "text"
      },
      "source": [
        "# Coding Challenge for those who might accept it:<br />\n",
        "Extend this to read in all the wins by each player over time and plot that using something like matplotlib and [maybe] numpy.  Given what I have written above and any documentation you find on line it should be pretty easy to scrape the data out of the page as it is just a big HTML table.<br />Plotting it with matplotlib wouldn't be hard either, [https://howtothink.readthedocs.io/en/latest/PvL_H.html](https://howtothink.readthedocs.io/en/latest/PvL_H.html) gives one way.  The other would be to use numpy ([https://numpy.org/devdocs/](https://numpy.org/devdocs/) together with matplotlib or another lib.<br />  Oh, and also add some error handling, please! :). \n",
        "\n",
        "### For those who question \"What this is\":<br /> \n",
        "This is a Jupyter Notebook that just happens to be embedded in the Google Suite so it allows us to use the normal RRD credentials to access it.  Here is a decent intro to the tool: [https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook).  This tool allows you to pretty much have all the power of Python in a browser (as the code runs on a remote server).  I have used it for all of the machine learning courses I have used on Coursera and it is pretty much the _de facto_ way of disseminating Python and data science learning nowadays.<br />The text cells are filled via Markdown, which is one of the goals for many of you.  Here is a great intro if you are still struggling with this: [https://colab.research.google.com/notebooks/markdown_guide.ipynb](https://colab.research.google.com/notebooks/markdown_guide.ipynb)\n",
        "\n",
        "### For those who question \"Why Python\":<br />\n",
        "Python is extremely easy-to-use and yet is powerful enough to run much of the current AI and machine learning algorithms in use today.  For this reason, and the fact that it is one of the top languages in use and in demand today ([https://insights.dice.com/2019/10/08/python-java-top-languages-employers/](https://insights.dice.com/2019/10/08/python-java-top-languages-employers/)).  With its libraries, there is almost nothing that it cannot do.  This fact alone, let alone that Evil Paul loves the language, makes it worth digging into a bit.  As I said, it is very easy to learn and the fact that I wrote the above code in less than an hour while waiting for my son is proof enough of that as I am no Python guru.<br />Expanding the horizons, thinking outside of the box of what we do everyday...these are part of what we do here.  I encourage you to embrace the opportunity here.\n"
      ]
    }
  ]
}